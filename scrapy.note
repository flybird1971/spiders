生成新项目     scrapy startproject <projectName>
生成spider    scrapy genspider [-t template] <name> <domain>
运行spider    scrapy crawl <spiderName>
scrapy fetch <url>  使用scrapy下载器下载指定url，并将获得内容送到标准输出
scrapy view <url>   使用scrapy下载器下载，并在浏览器中显示，可以用于查看下载数据与浏览器访问数据异同
scrapy shell        启动scrapy shell界面


列出所有spider scrapy list
运行contract检查 scrapy check

crawl
list
fetch
view



python与os交换
    import os
    os.getcwd()  获取当前所在目录
    os.chdir(param) 切换目录
    os.system(cmd)  执行系统shell命令

    ['F_OK', 'O_APPEND', 'O_BINARY', 'O_CREAT', 'O_EXCL', 'O_NOINHERIT',
    'O_RANDOM', 'O_RDONLY', 'O_RDWR', 'O_SEQUENTIAL', 'O_SHORT_LIVED',
    'O_TEMPORARY', 'O_TEXT', 'O_TRUNC', 'O_WRONLY', 'P_DETACH', 'P_NOWAIT',
    'P_NOWAITO', 'P_OVERLAY', 'P_WAIT', 'R_OK', 'SEEK_CUR', 'SEEK_END',
    'SEEK_SET', 'TMP_MAX', 'UserDict', 'W_OK', 'X_OK', '_Environ', '__all__',
    '__builtins__', '__doc__', '__file__', '__name__', '__package__', '_copy_reg',
    '_execvpe', '_exists', '_exit', '_get_exports_list', '_make_stat_result',
    '_make_statvfs_result', '_pickle_stat_result', '_pickle_statvfs_result',
    'abort', 'access', 'altsep', 'chdir', 'chmod', 'close', 'closerange',
    'curdir', 'defpath', 'devnull', 'dup', 'dup2', 'environ', 'errno', 'error',
    'execl', 'execle', 'execlp', 'execlpe', 'execv', 'execve', 'execvp', 'execvpe',
     'extsep', 'fdopen', 'fstat', 'fsync', 'getcwd', 'getcwdu', 'getenv', 'getpid',
     'isatty', 'kill', 'linesep', 'listdir', 'lseek', 'lstat', 'makedirs', 'mkdir',
     'name', 'open', 'pardir', 'path', 'pathsep', 'pipe', 'popen', 'popen2', 'popen3',
     'popen4', 'putenv', 'read', 'remove', 'removedirs', 'rename', 'renames', 'rmdir',
     'sep', 'spawnl', 'spawnle', 'spawnv', 'spawnve', 'startfile', 'stat', 'stat_float_times',
     'stat_result', 'statvfs_result', 'strerror', 'sys', 'system', 'tempnam', 'times','tmpfile',
     'tmpnam', 'umask', 'unlink', 'unsetenv', 'urandom', 'utime', 'waitpid', 'walk', 'write']
